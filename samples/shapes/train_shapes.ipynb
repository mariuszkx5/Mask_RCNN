{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "train_shapes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariuszkx5/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsRN7cqhBpsQ",
        "colab_type": "text"
      },
      "source": [
        "# Mask R-CNN - Train on Shapes Dataset\n",
        "\n",
        "\n",
        "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
        "\n",
        "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXnYTZ0e3E76",
        "colab_type": "text"
      },
      "source": [
        "samples/shapes/train_shapes.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0kGpa_OJquy",
        "colab_type": "code",
        "outputId": "d0c62cc6-662e-41c0-b0be-51487c170477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 24.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.29.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (47.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJWDgKKdCN5j",
        "colab_type": "code",
        "outputId": "8305541d-1a0b-4745-f1fb-957628abde68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vtLujuOJAOe",
        "colab_type": "code",
        "outputId": "77d507f0-e705-415b-ab77-fdac6152d52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsUXRLNqLJEE",
        "colab_type": "code",
        "outputId": "933596ec-cdf7-4ed3-f797-8d721eb674fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "pip install keras==2.1.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/c2/b0c2ece713e754d1692aa432ad682751cd1ad6abf7500a534558b1fbfbe7/Keras-2.1.0-py2.py3-none-any.whl (302kB)\n",
            "\r\u001b[K     |█                               | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.18.4)\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjd-qG4MvlQh",
        "colab_type": "code",
        "outputId": "bad828d1-a391-4893-ab68-c59d48229464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyjqdF1w4pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_2126QwgE8",
        "colab_type": "code",
        "outputId": "7df58b36-0ace-4a66-9565-948140aecafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "sys.path "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqrm-6PkBpsS",
        "colab_type": "code",
        "outputId": "45dc6199-ebf7-4d0b-ba4b-969b00c2efc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = '/content/drive/My Drive/Mask_RCNN'\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF5YcAoUBpsb",
        "colab_type": "text"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuQ3tmx0Bpse",
        "colab_type": "code",
        "outputId": "2270be66-6a63-4095-b9ce-24d4d0b64e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        }
      },
      "source": [
        "class ShapesConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"shapes\"\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    # Use a small epoch since the data is simple!!!!!!!!!!!!!!!!!!!1\n",
        "    STEPS_PER_EPOCH = 20\n",
        "\n",
        "    # use small validation steps since the epoch is small!!!!!!!!!!!!!!!\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = ShapesConfig()\n",
        "config.display()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     8\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 8\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  128\n",
            "IMAGE_META_SIZE                16\n",
            "IMAGE_MIN_DIM                  128\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [128 128   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           shapes\n",
            "NUM_CLASSES                    4\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                20\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           32\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               5\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idh3V5tvBpsj",
        "colab_type": "text"
      },
      "source": [
        "## Notebook Preferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvTdr_5SBpsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaVZe1YKBpsq",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Create a synthetic dataset\n",
        "\n",
        "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
        "\n",
        "* load_image()\n",
        "* load_mask()\n",
        "* image_reference()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIN4H-V-Bpsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ShapesDataset(utils.Dataset):\n",
        "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
        "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
        "    The images are generated on the fly. No file access required.\n",
        "    \"\"\"\n",
        "\n",
        "    def load_shapes(self, count, height, width):\n",
        "        \"\"\"Generate the requested number of synthetic images.\n",
        "        count: number of images to generate.\n",
        "        height, width: the size of the generated images.\n",
        "        \"\"\"\n",
        "        # Add classes\n",
        "        self.add_class(\"shapes\", 1, \"square\")\n",
        "        self.add_class(\"shapes\", 2, \"circle\")\n",
        "        self.add_class(\"shapes\", 3, \"triangle\")\n",
        "\n",
        "        # Add images\n",
        "        # Generate random specifications of images (i.e. color and\n",
        "        # list of shapes sizes and locations). This is more compact than\n",
        "        # actual images. Images are generated on the fly in load_image().\n",
        "        for i in range(count):\n",
        "            bg_color, shapes = self.random_image(height, width)\n",
        "            self.add_image(\"shapes\", image_id=i, path=None,\n",
        "                           width=width, height=height,\n",
        "                           bg_color=bg_color, shapes=shapes)\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Generate an image from the specs of the given image ID.\n",
        "        Typically this function loads the image from a file, but\n",
        "        in this case it generates the image on the fly from the\n",
        "        specs in image_info.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
        "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
        "        image = image * bg_color.astype(np.uint8)\n",
        "        for shape, color, dims in info['shapes']:\n",
        "            image = self.draw_shape(image, shape, dims, color)\n",
        "        return image\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the shapes data of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"shapes\":\n",
        "            return info[\"shapes\"]\n",
        "        else:\n",
        "            super(self.__class__).image_reference(self, image_id)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        shapes = info['shapes']\n",
        "        count = len(shapes)\n",
        "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
        "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
        "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
        "                                                shape, dims, 1)\n",
        "        # Handle occlusions\n",
        "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
        "        for i in range(count-2, -1, -1):\n",
        "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
        "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
        "        # Map class names to class IDs.\n",
        "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "\n",
        "    def draw_shape(self, image, shape, dims, color):\n",
        "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
        "        # Get the center x, y and the size s\n",
        "        x, y, s = dims\n",
        "        if shape == 'square':\n",
        "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
        "        elif shape == \"circle\":\n",
        "            cv2.circle(image, (x, y), s, color, -1)\n",
        "        elif shape == \"triangle\":\n",
        "            points = np.array([[(x, y-s),\n",
        "                                (x-s/math.sin(math.radians(60)), y+s),\n",
        "                                (x+s/math.sin(math.radians(60)), y+s),\n",
        "                                ]], dtype=np.int32)\n",
        "            cv2.fillPoly(image, points, color)\n",
        "        return image\n",
        "\n",
        "    def random_shape(self, height, width):\n",
        "        \"\"\"Generates specifications of a random shape that lies within\n",
        "        the given height and width boundaries.\n",
        "        Returns a tuple of three valus:\n",
        "        * The shape name (square, circle, ...)\n",
        "        * Shape color: a tuple of 3 values, RGB.\n",
        "        * Shape dimensions: A tuple of values that define the shape size\n",
        "                            and location. Differs per shape type.\n",
        "        \"\"\"\n",
        "        # Shape\n",
        "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
        "        # Color\n",
        "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
        "        # Center x, y\n",
        "        buffer = 20\n",
        "        y = random.randint(buffer, height - buffer - 1)\n",
        "        x = random.randint(buffer, width - buffer - 1)\n",
        "        # Size\n",
        "        s = random.randint(buffer, height//4)\n",
        "        return shape, color, (x, y, s)\n",
        "\n",
        "    def random_image(self, height, width):\n",
        "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
        "        Returns the background color of the image and a list of shape\n",
        "        specifications that can be used to draw the image.\n",
        "        \"\"\"\n",
        "        # Pick random background color\n",
        "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
        "        # Generate a few random shapes and record their\n",
        "        # bounding boxes\n",
        "        shapes = []\n",
        "        boxes = []\n",
        "        N = random.randint(1, 4)\n",
        "        for _ in range(N):\n",
        "            shape, color, dims = self.random_shape(height, width)\n",
        "            shapes.append((shape, color, dims))\n",
        "            x, y, s = dims\n",
        "            boxes.append([y-s, x-s, y+s, x+s])\n",
        "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
        "        # shapes covering each other\n",
        "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
        "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
        "        return bg_color, shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RaQ5TR3Bpsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training dataset\n",
        "dataset_train = ShapesDataset()\n",
        "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = ShapesDataset()\n",
        "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSpb-GphBps2",
        "colab_type": "code",
        "outputId": "f5fab83f-c68a-4f44-ea24-29cba98d0249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuxdJMUm82a2",
        "colab_type": "text"
      },
      "source": [
        "### **Task 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckHzMpQK0fuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_id in dataset_train.image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    img = Image.fromarray(image, 'RGB')    \n",
        "    img.save('Task5/' + str(image_id) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1SBhKk9Bps6",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-3_dG9aBps7",
        "colab_type": "code",
        "outputId": "5516aad6-7567-4ca8-9796-129dc441064b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "02GQgEQKBps-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZV5KRQlBptD",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "Train in two stages:\n",
        "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
        "\n",
        "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ZvE645hVBptE",
        "colab_type": "code",
        "outputId": "789cce04-ed5b-4599-b74f-7bbf425308db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=1, \n",
        "            layers='heads')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/My Drive/Mask_RCNN/logs/shapes20200606T1353/mask_rcnn_shapes_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2039: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 7/20 [=========>....................] - ETA: 7:54 - loss: 5.2135 - rpn_class_loss: 0.0852 - rpn_bbox_loss: 1.8341 - mrcnn_class_loss: 1.2687 - mrcnn_bbox_loss: 1.2223 - mrcnn_mask_loss: 0.8032"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-1:\n",
            "Process Process-2:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 631, in data_generator_task\n",
            "    self.queue.put(generator_output)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 631, in data_generator_task\n",
            "    self.queue.put(generator_output)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
            "    if not self._sem.acquire(block, timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
            "    if not self._sem.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "eP9rv-joBptI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also \n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=2, \n",
        "            layers=\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW1ezFZSBptN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save weights\n",
        "# Typically not needed because callbacks save after every epoch\n",
        "# Uncomment to save manually\n",
        "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
        "# model.keras_model.save_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFHU9C7NBptS",
        "colab_type": "text"
      },
      "source": [
        "## Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEKK2449BptT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(ShapesConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLg-vhitBptW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_val.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \n",
        "                           image_id, use_mini_mask=False)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uodk-CJ-Bptb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_val.class_names, r['scores'], ax=get_ax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlqWj-AjBpte",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnQMXcYBptf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "# Running on 10 images. Increase for better accuracy.\n",
        "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}